{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6973b933",
   "metadata": {},
   "source": [
    "#### News Classification usingAG_News Data\n",
    "\n",
    "\"World\", \"Sports\", \"Business\", \"Sci/Tech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b721c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdata in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from torchdata) (2.6.3)\n",
      "Requirement already satisfied: requests in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from torchdata) (2.32.5)\n",
      "Requirement already satisfied: torch>=2 in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from torchdata) (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from torch>=2->torchdata) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions in /home/dev-algo/.local/lib/python3.10/site-packages (from torch>=2->torchdata) (4.14.1)\n",
      "Requirement already satisfied: sympy in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from torch>=2->torchdata) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from torch>=2->torchdata) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from torch>=2->torchdata) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from jinja2->torch>=2->torchdata) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from requests->torchdata) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from requests->torchdata) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from requests->torchdata) (2026.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dev-algo/anaconda3/envs/WLV-AI/lib/python3.10/site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d69ec410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8ef5057",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchtext\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/WLV-AI/lib/python3.10/site-packages/torchtext/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[0;32m~/anaconda3/envs/WLV-AI/lib/python3.10/site-packages/torchtext/data/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Batch\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, TabularDataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexample\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Example\n",
      "File \u001b[0;32m~/anaconda3/envs/WLV-AI/lib/python3.10/site-packages/torchtext/data/batch.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBatch\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Defines a batch of examples along with its Fields.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Attributes:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Also stores the Variable for each column in the batch as an attribute.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/WLV-AI/lib/python3.10/site-packages/torch/__init__.py:457\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    459\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe1583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS()\n",
    "train_dataset = list(train_dataset)\n",
    "print(train_dataset[0])\n",
    "\n",
    "X_train_text, Y_train = [],[]\\\n",
    "for Y, X in train_dataset:\n",
    "    X_train_text.append(X)\n",
    "    Y_train.append(Y)\n",
    "    \n",
    "print(X_train_text[0])\n",
    "\n",
    "X_test_text, Y_test = [],[]\n",
    "for Y, X in test_dataset:\n",
    "    X_test_text.append(X)\n",
    "    Y_test.append(Y)\n",
    "\n",
    "print(X_test_text[0])\n",
    "\n",
    "unique_classes = list\n",
    "target_classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\n",
    "## Subtract 1 from the labels to make them zero-indexed\n",
    "Y_train, Y_test = np.array(Y_train) - 1, np.array(Y_test) - 1\n",
    "\n",
    "len(X_train_text), len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8bc77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tockenizer =  Tockenizer()\n",
    "tockenizer.fit_on_texts(X_train_text+X_test_text)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(tockenizer.word_index)))\n",
    "\n",
    "max_tokens= 50\n",
    "## Vectorizing data to keep max_tokens words per sample.\n",
    "X_train_vect = pad_sequences(tockenizer.texts_to_sequences(X_train_text), maxlen=max_tokens, padding='post', truncating='post', value=0)\n",
    "X_test_vect = pad_sequences(tockenizer.texts_to_sequences(X_test_text), maxlen=max_tokens, padding='post', truncating='post', value=0)\n",
    "\n",
    "# Check the shape of the vectorized data\n",
    "print(\"Shape of X_train_vect: {}\".format(X_train_vect.shape))\n",
    "print(\"Shape of X_test_vect: {}\".format(X_test_vect.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is word 444\n",
    "print(\"Word corresponding to index 444: {}\".format(tockenizer.index_word[444]))\n",
    "\n",
    "## How many times it comes in first text document   \n",
    "print(X_train_vect[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6406b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embed_len = 50\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=len(tockenizer.word_index)+1, output_dim=embed_len, input_length=max_tokens),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(len(target_classes), activation='softmax')\n",
    "]) \n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eaeff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_vect, Y_train, epochs=10, batch_size=128, validation_data=(X_test_vect, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55091f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "train_preds = model.predict(X_train_vect)\n",
    "test_preds = model.predict(X_test_vect)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(Y_train, np.argmax(train_preds, axis=1))))\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(Y_test, np.argmax(test_preds, axis=1))))\n",
    "print(\"Classification Report:\\n {}\".format(classification_report(Y_test, np.argmax(test_preds, axis=1), target_names=target_classes)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WLV-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
